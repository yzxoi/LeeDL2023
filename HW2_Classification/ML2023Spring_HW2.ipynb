{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8W9IwwNMw-c4",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# IMPORTANT: SOME KAGGLE DATA SOURCES ARE PRIVATE\n",
        "# RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES.\n",
        "import kagglehub\n",
        "kagglehub.login()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h9goQLpGw-c6",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "ml2023spring_hw2_path = kagglehub.competition_download('ml2023spring-hw2')\n",
        "\n",
        "print('Data source import complete.')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "IPython.notebook.set_autosave_interval(5000)"
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Autosaving every 5 seconds\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import logging\n",
        "\n",
        "nblog = open(\"nb.log\", \"a+\")\n",
        "sys.stdout.echo = nblog\n",
        "sys.stderr.echo = nblog\n",
        "\n",
        "get_ipython().log.handlers[0].stream = nblog\n",
        "get_ipython().log.setLevel(logging.INFO)\n",
        "\n",
        "%autosave 5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OYlaRwNu7ojq"
      },
      "source": [
        "# **Homework 2: Phoneme Classification**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A7DRC5V7_8A5"
      },
      "source": [
        "Objectives:\n",
        "* Solve a classification problem with deep neural networks (DNNs).\n",
        "* Understand recursive neural networks (RNNs).\n",
        "\n",
        "If you have any questions, please contact the TAs via TA hours, NTU COOL, or email to mlta-2023-spring@googlegroups.com"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pADUiYODJE1O"
      },
      "source": [
        "# Some Utility Functions\n",
        "**Fixes random number generator seeds for reproducibility.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-02-22T15:19:14.467496Z",
          "iopub.status.busy": "2023-02-22T15:19:14.466839Z",
          "iopub.status.idle": "2023-02-22T15:19:17.007531Z",
          "shell.execute_reply": "2023-02-22T15:19:17.006459Z",
          "shell.execute_reply.started": "2023-02-22T15:19:14.467381Z"
        },
        "id": "BsZKgBZQJjaE",
        "trusted": true,
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import random\n",
        "\n",
        "def same_seeds(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    torch.backends.cudnn.deterministic = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_L_4anls8Drv"
      },
      "source": [
        "**Helper functions to pre-process the training data from raw MFCC features of each utterance.**\n",
        "\n",
        "A phoneme may span several frames and is dependent to past and future frames. \\\n",
        "Hence we concatenate neighboring phonemes for training to achieve higher accuracy. The **concat_feat** function concatenates past and future k frames (total 2k+1 = n frames), and we predict the center frame.\n",
        "\n",
        "Feel free to modify the data preprocess functions, but **do not drop any frame** (if you modify the functions, remember to check that the number of frames are the same as mentioned in the slides)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-02-22T15:19:17.010439Z",
          "iopub.status.busy": "2023-02-22T15:19:17.009831Z",
          "iopub.status.idle": "2023-02-22T15:19:17.031164Z",
          "shell.execute_reply": "2023-02-22T15:19:17.030072Z",
          "shell.execute_reply.started": "2023-02-22T15:19:17.0104Z"
        },
        "id": "IJjLT8em-y9G",
        "trusted": true,
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "\n",
        "def load_feat(path):\n",
        "    feat = torch.load(path)\n",
        "    return feat\n",
        "\n",
        "def shift(x, n):\n",
        "    if n < 0:\n",
        "        left = x[0].repeat(-n, 1)\n",
        "        right = x[:n]\n",
        "    elif n > 0:\n",
        "        right = x[-1].repeat(n, 1)\n",
        "        left = x[n:]\n",
        "    else:\n",
        "        return x\n",
        "\n",
        "    return torch.cat((left, right), dim=0)\n",
        "\n",
        "def concat_feat(x, concat_n):\n",
        "    assert concat_n % 2 == 1 # n must be odd\n",
        "    if concat_n < 2:\n",
        "        return x\n",
        "    seq_len, feature_dim = x.size(0), x.size(1)\n",
        "    x = x.repeat(1, concat_n)\n",
        "    x = x.view(seq_len, concat_n, feature_dim).permute(1, 0, 2) # concat_n, seq_len, feature_dim\n",
        "    mid = (concat_n // 2)\n",
        "    for r_idx in range(1, mid+1):\n",
        "        x[mid + r_idx, :] = shift(x[mid + r_idx], r_idx)\n",
        "        x[mid - r_idx, :] = shift(x[mid - r_idx], -r_idx)\n",
        "\n",
        "    return x.permute(1, 0, 2).view(seq_len, concat_n * feature_dim)\n",
        "\n",
        "# def preprocess_data(split, feat_dir, phone_path, concat_nframes, train_ratio=1):\n",
        "#     class_num = 41 # NOTE: pre-computed, should not need change\n",
        "\n",
        "#     if split == 'train' or split == 'val':\n",
        "#         mode = 'train'\n",
        "#     elif split == 'test':\n",
        "#         mode = 'test'\n",
        "#     else:\n",
        "#         raise ValueError('Invalid \\'split\\' argument for dataset: PhoneDataset!')\n",
        "\n",
        "#     label_dict = {}\n",
        "#     if mode == 'train':\n",
        "#         for line in open(os.path.join(phone_path, f'{mode}_labels.txt')).readlines():\n",
        "#             line = line.strip('\\n').split(' ')\n",
        "#             label_dict[line[0]] = [int(p) for p in line[1:]]\n",
        "\n",
        "#         # split training and validation data\n",
        "#         usage_list = open(os.path.join(phone_path, 'train_split.txt')).readlines()\n",
        "#         random.shuffle(usage_list)\n",
        "#         train_len = int(len(usage_list) * train_ratio)\n",
        "#         usage_list = usage_list[:train_len] if split == 'train' else usage_list[train_len:]\n",
        "\n",
        "#     elif mode == 'test':\n",
        "#         usage_list = open(os.path.join(phone_path, 'test_split.txt')).readlines()\n",
        "\n",
        "#     usage_list = [line.strip('\\n') for line in usage_list]\n",
        "#     print('[Dataset] - # phone classes: ' + str(class_num) + ', number of utterances for ' + split + ': ' + str(len(usage_list)))\n",
        "\n",
        "#     max_len = 3000000\n",
        "#     X = torch.empty(max_len, 39 * concat_nframes)\n",
        "#     if mode == 'train':\n",
        "#         y = torch.empty(max_len, dtype=torch.long)\n",
        "\n",
        "#     idx = 0\n",
        "#     for i, fname in tqdm(enumerate(usage_list)):\n",
        "#         feat = load_feat(os.path.join(feat_dir, mode, f'{fname}.pt'))\n",
        "#         cur_len = len(feat)\n",
        "#         feat = concat_feat(feat, concat_nframes)\n",
        "#         if mode == 'train':\n",
        "#           label = torch.LongTensor(label_dict[fname])\n",
        "\n",
        "#         X[idx: idx + cur_len, :] = feat\n",
        "#         if mode == 'train':\n",
        "#           y[idx: idx + cur_len] = label\n",
        "\n",
        "#         idx += cur_len\n",
        "\n",
        "#     X = X[:idx, :]\n",
        "#     if mode == 'train':\n",
        "#       y = y[:idx]\n",
        "\n",
        "#     print(f'[INFO] {split} set')\n",
        "#     print(X.shape)\n",
        "#     if mode == 'train':\n",
        "#       print(y.shape)\n",
        "#       return X, y\n",
        "#     else:\n",
        "#       return X\n",
        "def preprocess_data(split, feat_dir, phone_path, concat_nframes, train_ratio=1):\n",
        "    import random\n",
        "    class_num = 41\n",
        "\n",
        "    if split == 'train' or split == 'val':\n",
        "        mode = 'train'\n",
        "    elif split == 'test':\n",
        "        mode = 'test'\n",
        "    else:\n",
        "        raise ValueError('Invalid split')\n",
        "\n",
        "    label_dict = {}\n",
        "    if mode == 'train':\n",
        "        with open(os.path.join(phone_path, f'{mode}_labels.txt')) as f:\n",
        "            for line in f:\n",
        "                line = line.strip().split(' ')\n",
        "                label_dict[line[0]] = [int(p) for p in line[1:]]\n",
        "\n",
        "        usage_list = open(os.path.join(phone_path, 'train_split.txt')).readlines()\n",
        "        random.shuffle(usage_list)\n",
        "        train_len = int(len(usage_list) * train_ratio)\n",
        "        usage_list = usage_list[:train_len] if split == 'train' else usage_list[train_len:]\n",
        "    else:\n",
        "        usage_list = open(os.path.join(phone_path, 'test_split.txt')).readlines()\n",
        "\n",
        "    usage_list = [line.strip() for line in usage_list]\n",
        "    print(f'[Dataset] {split} - samples: {len(usage_list)}')\n",
        "\n",
        "    X, y = [], []\n",
        "\n",
        "    for fname in tqdm(usage_list):\n",
        "        feat = load_feat(os.path.join(feat_dir, mode, f'{fname}.pt'))  # (T, 39)\n",
        "        feat = concat_feat(feat, concat_nframes)  # (T, 39 * n)\n",
        "\n",
        "        X.append(feat)\n",
        "        if mode == 'train':\n",
        "            label = torch.LongTensor(label_dict[fname])\n",
        "            assert label.shape[0] == feat.shape[0], f\"[{fname}] Label/Feature mismatch: {label.shape[0]} vs {feat.shape[0]}\"\n",
        "            y.append(label)\n",
        "\n",
        "    print(f'[INFO] {split} set loaded.')\n",
        "    if mode == 'train':\n",
        "        return X, y\n",
        "    else:\n",
        "        return X"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "us5XW_x6udZQ"
      },
      "source": [
        "# Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-02-22T15:19:17.033523Z",
          "iopub.status.busy": "2023-02-22T15:19:17.033044Z",
          "iopub.status.idle": "2023-02-22T15:19:17.046921Z",
          "shell.execute_reply": "2023-02-22T15:19:17.04599Z",
          "shell.execute_reply.started": "2023-02-22T15:19:17.033471Z"
        },
        "id": "Fjf5EcmJtf4e",
        "trusted": true,
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class LibriDataset(Dataset):\n",
        "    def __init__(self, X, y=None):\n",
        "        self.data = X\n",
        "        if y is not None:\n",
        "            self.label = torch.LongTensor(y)\n",
        "        else:\n",
        "            self.label = None\n",
        "\n",
        "    # def __getitem__(self, idx):\n",
        "    #     if self.label is not None:\n",
        "    #         return self.data[idx], self.label[idx]\n",
        "    #     else:\n",
        "    #         return self.data[idx]\n",
        "    def __getitem__(self, idx):\n",
        "        x = self.data[idx]\n",
        "        length = x.shape[0]\n",
        "        if self.label is not None:\n",
        "            y = self.label[idx]\n",
        "            return x, y, length\n",
        "        else:\n",
        "            return x, length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class LibriSequenceDataset(Dataset):\n",
        "    def __init__(self, data_list, label_list=None):\n",
        "        self.data = data_list\n",
        "        self.label = label_list\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if self.label is not None:\n",
        "            return self.data[idx], self.label[idx], self.data[idx].shape[0]\n",
        "        else:\n",
        "            return self.data[idx], self.data[idx].shape[0]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "def collate_fn(batch):\n",
        "    for b in batch:\n",
        "        if b[1].shape[0] == 0:\n",
        "            print(f\"[collate_fn] Found empty label: x.shape={b[0].shape}, y.shape={b[1].shape}\")\n",
        "    xs, ys, lengths = zip(*batch)  # batch: list of (x, y, length)\n",
        "    xs_pad = pad_sequence(xs, batch_first=True)          # (B, T_max, 39)\n",
        "    ys_pad = pad_sequence(ys, batch_first=True, padding_value=-100)  # (B, T_max)\n",
        "    return xs_pad, ys_pad, torch.tensor(lengths)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IRqKNvNZwe3V"
      },
      "source": [
        "# Model\n",
        "Feel free to modify the structure of the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-02-22T15:19:17.050655Z",
          "iopub.status.busy": "2023-02-22T15:19:17.050236Z",
          "iopub.status.idle": "2023-02-22T15:19:17.060412Z",
          "shell.execute_reply": "2023-02-22T15:19:17.059172Z",
          "shell.execute_reply.started": "2023-02-22T15:19:17.050624Z"
        },
        "id": "Bg-GRd7ywdrL",
        "trusted": true,
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim, dropout=0):\n",
        "        super(BasicBlock, self).__init__()\n",
        "\n",
        "        self.block = nn.Sequential(\n",
        "            nn.Linear(input_dim, output_dim),\n",
        "            nn.BatchNorm1d(output_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.block(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class Classifier(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim=41, hidden_layers=1, hidden_dim=256, dropout=0.3):\n",
        "        super(Classifier, self).__init__()\n",
        "\n",
        "        self.fc = nn.Sequential(\n",
        "            BasicBlock(input_dim, hidden_dim),\n",
        "            *[BasicBlock(hidden_dim, hidden_dim, dropout) for _ in range(hidden_layers)],\n",
        "            nn.Linear(hidden_dim, output_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "    \n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "\n",
        "class RNNClassifier(nn.Module):\n",
        "    def __init__(self, feat_dim, hidden_dim=256, num_layers=3, num_classes=41,\n",
        "                 bidirectional=True, dropout=0.2):\n",
        "        super().__init__()\n",
        "\n",
        "        self.bidirectional = bidirectional\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "        self.input_norm = nn.LayerNorm(feat_dim)\n",
        "        self.input_dropout = nn.Dropout(dropout)\n",
        "\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=feat_dim,\n",
        "            hidden_size=hidden_dim,\n",
        "            num_layers=num_layers,\n",
        "            batch_first=True,\n",
        "            bidirectional=bidirectional,\n",
        "            dropout=dropout if num_layers > 1 else 0.0\n",
        "        )\n",
        "\n",
        "        self.output_norm = nn.LayerNorm(hidden_dim * (2 if bidirectional else 1))\n",
        "        self.output_dropout = nn.Dropout(dropout)\n",
        "\n",
        "        self.output_proj = nn.Linear(\n",
        "            hidden_dim * (2 if bidirectional else 1),\n",
        "            num_classes\n",
        "        )\n",
        "\n",
        "    def forward(self, x, lengths):  # x: (B, T, D), lengths: list[int]\n",
        "\n",
        "        x = self.input_norm(x)\n",
        "        x = self.input_dropout(x)\n",
        "\n",
        "        packed = pack_padded_sequence(x, lengths=lengths, batch_first=True, enforce_sorted=False)\n",
        "        packed_out, _ = self.lstm(packed)\n",
        "        out, _ = pad_packed_sequence(packed_out, batch_first=True)  # (B, T, H)\n",
        "\n",
        "        out = self.output_norm(out)\n",
        "        out = self.output_dropout(out)\n",
        "\n",
        "        logits = self.output_proj(out)  # (B, T, num_classes)\n",
        "        return logits\n",
        "\n",
        "class ConvLSTMClassifier(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, num_layers, num_classes=41,\n",
        "                 conv_channels=64, bidirectional=True, dropout=0.4):\n",
        "        super().__init__()\n",
        "        # Conv1D expects input: (B, D_in, T), so we'll permute before & after\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv1d(in_channels=input_dim, out_channels=conv_channels, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm1d(conv_channels),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=conv_channels,\n",
        "            hidden_size=hidden_dim,\n",
        "            num_layers=num_layers,\n",
        "            bidirectional=bidirectional,\n",
        "            batch_first=True,\n",
        "            dropout=dropout if num_layers > 1 else 0.0\n",
        "        )\n",
        "        self.classifier = nn.Linear(hidden_dim * (2 if bidirectional else 1), num_classes)\n",
        "\n",
        "    def forward(self, x):  # x: (B, T, D)\n",
        "        x = x.permute(0, 2, 1)                # → (B, D, T)\n",
        "        x = self.conv(x)                      # → (B, C, T)\n",
        "        x = x.permute(0, 2, 1)                # → (B, T, C)\n",
        "\n",
        "        out, _ = self.lstm(x)                 # → (B, T, H)\n",
        "        mid = out.size(1) // 2\n",
        "        out = out[:, mid, :]                  # 中间帧\n",
        "        return self.classifier(out)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TlIq8JeqvvHC"
      },
      "source": [
        "# Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-02-22T15:19:17.061941Z",
          "iopub.status.busy": "2023-02-22T15:19:17.061666Z",
          "iopub.status.idle": "2023-02-22T15:19:17.075782Z",
          "shell.execute_reply": "2023-02-22T15:19:17.074564Z",
          "shell.execute_reply.started": "2023-02-22T15:19:17.061914Z"
        },
        "id": "iIHn79Iav1ri",
        "trusted": true,
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DEVICE: cuda\n"
          ]
        }
      ],
      "source": [
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from sklearn.model_selection import KFold\n",
        "from tqdm import tqdm\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "from torch.optim.lr_scheduler import StepLR, ReduceLROnPlateau\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "\n",
        "config = {\n",
        "    'concat_nframes': 61,\n",
        "    'learning_rate': 5e-3,\n",
        "    'save_path': './model.ckpt',\n",
        "    'dropout': 0.2,\n",
        "    'conv_channels': 64,\n",
        "    'weight_decay': 1e-4\n",
        "}\n",
        "\n",
        "# data prarameters\n",
        "concat_nframes = config['concat_nframes']              # the number of frames to concat with, n must be odd (total 2k+1 = n frames)\n",
        "k = 5\n",
        "\n",
        "# training parameters\n",
        "seed = 5201314                   # random seed\n",
        "batch_size = 16                # batch size\n",
        "num_epoch = 300                   # the number of training epoch\n",
        "early_stop = 20                # the number of early stop\n",
        "learning_rate = config['learning_rate']           # learning rate\n",
        "model_path = './model.ckpt'     # the path where the checkpoint will be saved\n",
        "\n",
        "# model parameters\n",
        "input_dim = 39 * concat_nframes # the input dim of the model, you should not change the value\n",
        "hidden_layers = 4               # the number of hidden layers\n",
        "hidden_dim = 256                # the hidden dim\n",
        "\n",
        "class LabelSmoothingLoss(nn.Module):\n",
        "    def __init__(self, classes, smoothing=0.1, ignore_index=-100):\n",
        "        super(LabelSmoothingLoss, self).__init__()\n",
        "        self.confidence = 1.0 - smoothing\n",
        "        self.smoothing = smoothing\n",
        "        self.cls = classes\n",
        "        self.ignore_index = ignore_index\n",
        "        self.log_softmax = nn.LogSoftmax(dim=-1)\n",
        "\n",
        "    def forward(self, x, target):\n",
        "        \"\"\"\n",
        "        x: (B, C) logits\n",
        "        target: (B,) int64 labels with possible ignore_index\n",
        "        \"\"\"\n",
        "        log_probs = self.log_softmax(x)  # (B, C)\n",
        "\n",
        "        # Create mask for valid targets\n",
        "        mask = (target != self.ignore_index)\n",
        "        target = target[mask]         # (N,)\n",
        "        log_probs = log_probs[mask]   # (N, C)\n",
        "\n",
        "        if target.numel() == 0:\n",
        "            return torch.tensor(0.0, device=x.device, requires_grad=True)\n",
        "\n",
        "        # One-hot with smoothing\n",
        "        true_dist = torch.full_like(log_probs, self.smoothing / (self.cls - 1))\n",
        "        true_dist.scatter_(1, target.unsqueeze(1), self.confidence)\n",
        "\n",
        "        loss = torch.sum(-true_dist * log_probs, dim=1)  # (N,)\n",
        "        return loss.mean()\n",
        "    \n",
        "fold_accuracies = []\n",
        "\n",
        "def train_one_fold(fold, model, train_loader, val_loader,\n",
        "    epochs, lr, device, ckpt_path, writer, weights):\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss(weight=weights)\n",
        "    # criterion = LabelSmoothingLoss(classes=41, smoothing=0.1, ignore_index=-100)\n",
        "    # criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=config['weight_decay'])\n",
        "    # scheduler = CosineAnnealingLR(\n",
        "\t# \toptimizer,\n",
        "\t# \tT_max=20,     # 前 100 个 epoch 为一个完整退火周期\n",
        "\t# \teta_min=1e-5\n",
        "\t# )\n",
        "    # scheduler = StepLR(\n",
        "    #     optimizer,\n",
        "    #     step_size=20,     # 每 10 个 epoch 降一次\n",
        "    #     gamma=0.5         # 学习率变为原来的一半\n",
        "    # )\n",
        "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.8, patience=5, threshold=0.001)\n",
        "    best_val_acc = 0.0\n",
        "    global fold_accuracies\n",
        "    # loss_fn = nn.CrossEntropyLoss(ignore_index=-100)\n",
        "\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        print(f\"\\n=== Epoch {epoch} ===\")\n",
        "        # — Training — \n",
        "        model.train()\n",
        "        train_loss = train_correct = train_total = 0\n",
        "        train_pbar = tqdm(enumerate(train_loader), \n",
        "                      total=len(train_loader), \n",
        "                      desc=f\"Train Epoch {epoch}\", \n",
        "                      leave=True)\n",
        "        for step,(feats, labels, lengths) in train_pbar:\n",
        "            # feats, labels = feats.to(device), labels.to(device)\n",
        "            # feat_dim = feats.size(1) // concat_nframes\n",
        "            # feats = feats.view(-1, concat_nframes, feat_dim).to(device)\n",
        "            # labels = labels.to(device)\n",
        "            feats = feats.to(device)\n",
        "            labels = labels.to(device)\n",
        "            lengths = lengths.to('cpu')  # 注意 pack_padded_sequence 要用 CPU 上的长度列表\n",
        "            optimizer.zero_grad()\n",
        "            out = model(feats, lengths)\n",
        "\n",
        "\n",
        "            # out = model(feats)\n",
        "            # loss = criterion(out, labels)\n",
        "            loss = criterion(out.view(-1, out.size(-1)), labels.view(-1))\n",
        "\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=5.0)\n",
        "            optimizer.step()\n",
        "\n",
        "            # pred = out.argmax(1)\n",
        "            # train_correct += (pred == labels).sum().item()\n",
        "            # train_total += feats.size(0)\n",
        "            pred=out.argmax(dim=-1)\n",
        "            mask = (labels != -100)\n",
        "            correct = (pred == labels) & mask\n",
        "            train_correct += correct.sum().item()\n",
        "            train_total += mask.sum().item()\n",
        "            train_loss += loss.item() * mask.sum().item()\n",
        "            train_pbar.set_postfix(loss=loss.item(), acc=train_correct/train_total if train_total > 0 else 0)\n",
        "\n",
        "        train_loss /= train_total\n",
        "        train_acc  = train_correct / train_total\n",
        "\n",
        "        # — Validation —\n",
        "        model.eval()\n",
        "        val_loss = val_correct = val_total = 0\n",
        "        all_preds = []\n",
        "        all_labels = []\n",
        "        val_pbar = tqdm(enumerate(val_loader), \n",
        "                      total=len(val_loader), \n",
        "                      desc=f\"Val Epoch {epoch}\", \n",
        "                      leave=True)\n",
        "        with torch.no_grad():\n",
        "            for step,(feats, labels, lengths) in val_pbar:\n",
        "                # feats, labels = feats.to(device), labels.to(device)\n",
        "                # feat_dim = feats.size(1) // concat_nframes\n",
        "                # feats = feats.view(-1, concat_nframes, feat_dim).to(device)\n",
        "                # labels = labels.to(device)\n",
        "                feats = feats.to(device)\n",
        "                labels = labels.to(device)\n",
        "                lengths = lengths.to('cpu')  # 注意 pack_padded_sequence 要用 CPU 上的长度列表\n",
        "                out = model(feats, lengths)\n",
        "                loss = criterion(out.view(-1, out.size(-1)), labels.view(-1))\n",
        "\n",
        "                # out = model(feats)\n",
        "                # loss = criterion(out, labels)\n",
        "\n",
        "                # val_loss += loss.item() * feats.size(0)\n",
        "                # pred = out.argmax(1)\n",
        "                # val_correct += (pred == labels).sum().item()\n",
        "                # val_total += feats.size(0)\n",
        "                # all_preds.extend(pred.cpu().numpy())\n",
        "                # all_labels.extend(labels.cpu().numpy())\n",
        "                pred = out.argmax(dim=-1)            # (B, T)\n",
        "                mask = (labels != -100)              # padding mask\n",
        "                correct = ((pred == labels) & mask).sum().item()\n",
        "                total = mask.sum().item()\n",
        "                val_correct += correct\n",
        "                val_total += total\n",
        "                val_loss += loss.item() * mask.sum().item()\n",
        "                all_preds.extend(pred[mask].cpu().numpy())\n",
        "                all_labels.extend(labels[mask].cpu().numpy())\n",
        "                val_pbar.set_postfix(loss=loss.item(), acc=val_correct/val_total if val_total > 0 else 0)\n",
        "\n",
        "        val_loss /= val_total\n",
        "        val_acc  = val_correct / val_total\n",
        "        val_f1 = f1_score(all_labels, all_preds, average='macro')\n",
        "        scheduler.step(val_acc)\n",
        "\n",
        "        # — Log to TensorBoard under fold subdir —\n",
        "        writer.add_scalar(f\"Fold{fold}/Loss/Train\", train_loss, epoch)\n",
        "        writer.add_scalar(f\"Fold{fold}/Loss/Val\",   val_loss,   epoch)\n",
        "        writer.add_scalar(f\"Fold{fold}/Acc/Train\",  train_acc,  epoch)\n",
        "        writer.add_scalar(f\"Fold{fold}/Acc/Val\",    val_acc,    epoch)\n",
        "        writer.add_scalar(f\"Fold{fold}/LR\", scheduler.get_last_lr()[0], epoch)\n",
        "        writer.add_scalar(f\"Fold{fold}/F1/Val\", val_f1, epoch)\n",
        "\n",
        "        if val_acc > best_val_acc:\n",
        "            best_val_acc = val_acc\n",
        "            if len(fold_accuracies) == 0 or best_val_acc > max(fold_accuracies):\n",
        "                torch.save(model.state_dict(), f\"{ckpt_path}.ckpt\")\n",
        "            early_stop_count = 0\n",
        "        else:\n",
        "            early_stop_count += 1\n",
        "        \n",
        "        if early_stop_count >= early_stop:\n",
        "            print(f\"Early stopping at epoch {epoch}!\")\n",
        "            break\n",
        "    writer.add_hparams(\n",
        "        hparam_dict={\n",
        "            'concat_nframes': concat_nframes,\n",
        "            'learning_rate': learning_rate,\n",
        "            'batch_size': batch_size\n",
        "        },\n",
        "        metric_dict={\n",
        "            'train_loss': train_loss,\n",
        "            'train_acc': train_acc,\n",
        "            'val_loss': val_loss,\n",
        "            'val_acc': val_acc\n",
        "        }\n",
        "    )\n",
        "    return best_val_acc\n",
        "\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "import gc\n",
        "import optuna\n",
        "\n",
        "same_seeds(seed)\n",
        "train_ratio = 0.8\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f'DEVICE: {device}')\n",
        "\n",
        "def objective(trial):\n",
        "    if trial != None:\n",
        "        print('\\nNew trial here')\n",
        "        print(f\"Trial: {trial.number}\")\n",
        "        # 定义需要调优的超参数空间\n",
        "        config['concat_nframes'] = trial.suggest_int('concat_nframes', 0, 10) * 2 + 1\n",
        "    concat_nframes = config['concat_nframes']\n",
        "    input_dim = 39 * concat_nframes\n",
        "        # config['betas'][0] = trial.suggest_float('beta1', 0.89, 0.9)\n",
        "        # config['betas'][1] = trial.suggest_float('beta2', 0.99, 0.9999)\n",
        "        # config['batch_size'] = trial.suggest_categorical('batch_size', [128])\n",
        "        # config['k'] = trial.suggest_int('k_feats', 5, 32)\n",
        "    # 打印所需的超参数\n",
        "    print(f'''hyper-parameter:\n",
        "        lr: {config['learning_rate']},\n",
        "        concat_nframes: {config['concat_nframes']}''')\n",
        "    \n",
        "\t# preprocess data\n",
        "    train_X, train_y = preprocess_data(split='train', feat_dir='./mlhw2/libriphone/feat', phone_path='./mlhw2/libriphone', concat_nframes=concat_nframes, train_ratio=train_ratio)\n",
        "    val_X, val_y = preprocess_data(split='val', feat_dir='./mlhw2/libriphone/feat', phone_path='./mlhw2/libriphone', concat_nframes=concat_nframes, train_ratio=train_ratio)\n",
        "    if isinstance(train_y, list):\n",
        "        y_train = np.concatenate([y.numpy() if isinstance(y, torch.Tensor) else np.array(y) for y in train_y])\n",
        "    else:\n",
        "        y_train = train_y.numpy()\n",
        "    classes = np.arange(41)\n",
        "    raw_weights = compute_class_weight(\n",
        "        class_weight='balanced',\n",
        "        classes=classes,\n",
        "        y=y_train\n",
        "    )\n",
        "    adjusted_weights = raw_weights ** 0.4  # 平滑惩罚力度\n",
        "    weights = torch.tensor(adjusted_weights, dtype=torch.float).to(device)\n",
        "\n",
        "    # get dataset\n",
        "    train_set = LibriSequenceDataset(train_X, train_y)\n",
        "    val_set = LibriSequenceDataset(val_X, val_y)\n",
        "    for i, (x, y) in enumerate(zip(train_X, train_y)):\n",
        "        if len(y) == 0 or len(x) == 0:\n",
        "            print(f\"Empty sample at index {i}: x.shape={x.shape}, y.shape={y.shape}\")\n",
        "\n",
        "    # remove raw feature to save memory\n",
        "    del train_X, train_y, val_X, val_y\n",
        "    gc.collect()\n",
        "\n",
        "    # get dataloader\n",
        "    # train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
        "    # val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    train_loader = DataLoader(\n",
        "        train_set,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,\n",
        "        collate_fn=collate_fn\n",
        "    )\n",
        "    val_loader = DataLoader(\n",
        "        val_set,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False,\n",
        "        collate_fn=collate_fn\n",
        "    )\n",
        "\n",
        "    # model = Classifier(input_dim=input_dim, hidden_layers=hidden_layers, hidden_dim=hidden_dim, dropout=config['dropout']).to(device)\n",
        "    # — Option B: RNN sequence labeling —\n",
        "    feat_dim = input_dim // concat_nframes\n",
        "    model = RNNClassifier(\n",
        "        input_dim, hidden_dim=hidden_dim, num_layers=hidden_layers,\n",
        "        num_classes=41, bidirectional=True, dropout=config['dropout']\n",
        "    ).to(device)\n",
        "    # model = ConvLSTMClassifier(\n",
        "    #     input_dim=feat_dim,\n",
        "    #     hidden_dim=hidden_dim,\n",
        "    #     num_layers=hidden_layers,\n",
        "    #     num_classes=41,\n",
        "    #     conv_channels=config['conv_channels'],\n",
        "    #     bidirectional=True,\n",
        "    #     dropout=config['dropout']\n",
        "    # ).to(device)\n",
        "\n",
        "    print(\"Model summary:\")\n",
        "    for name, param in model.named_parameters():\n",
        "        print(name, param.numel())\n",
        "\n",
        "    # ── TensorBoard writer per fold ──\n",
        "    if trial != None:\n",
        "        writer = SummaryWriter(log_dir=f\"./runs/nofold{trial.number}\")\n",
        "    else:\n",
        "        writer = SummaryWriter()\n",
        "    global fold_accuracies\n",
        "    fold_accuracies = []\n",
        "\n",
        "    if trial != None:\n",
        "        best_val = train_one_fold(1, model, train_loader, val_loader,\n",
        "                        epochs=num_epoch, lr=learning_rate, device=device, ckpt_path=f\"./model{trial.number}\", writer=writer, weights = weights)\n",
        "    else:\n",
        "        best_val = train_one_fold(1, model, train_loader, val_loader,\n",
        "                        epochs=num_epoch, lr=learning_rate, device=device, ckpt_path=f\"./model\", writer=writer, weights = weights)\n",
        "    \n",
        "    writer.close()\n",
        "\n",
        "    print(f\"best val acc: {best_val:.4f}\\n\")\n",
        "    avg_acc = best_val\n",
        "\n",
        "\t# # (Re)load your full dataset once:\n",
        "    # full_X, full_y = preprocess_data(\n",
        "\t# \tsplit=\"train\",\n",
        "\t# \tfeat_dir='./mlhw2/libriphone/feat',\n",
        "\t# \tphone_path='./mlhw2/libriphone',\n",
        "\t# \tconcat_nframes=concat_nframes,\n",
        "\t# \ttrain_ratio=1\n",
        "\t# )\n",
        "    # full_dataset = LibriDataset(full_X, full_y)\n",
        "\n",
        "    # y_train = full_y.numpy()\n",
        "    # classes = np.arange(41)\n",
        "    # raw_weights = compute_class_weight(\n",
        "    #     class_weight='balanced',\n",
        "    #     classes=classes,\n",
        "    #     y=y_train\n",
        "    # )\n",
        "    # adjusted_weights = raw_weights ** 0.3  # 平滑惩罚力度\n",
        "    # weights = torch.tensor(adjusted_weights, dtype=torch.float).to(device)\n",
        "    # del full_X, full_y\n",
        "    # gc.collect()\n",
        "\n",
        "    # kf = KFold(n_splits=k, shuffle=True, random_state=seed)\n",
        "\n",
        "    # fold_accuracies = []\n",
        "    \n",
        "    # for fold, (train_idx, val_idx) in enumerate(kf.split(full_dataset), 1):\n",
        "\t# \t# ── Prepare subset loaders ──\n",
        "    #     train_sub = Subset(full_dataset, train_idx)\n",
        "    #     val_sub   = Subset(full_dataset, val_idx)\n",
        "    #     train_loader = DataLoader(train_sub, batch_size=batch_size, shuffle=True)\n",
        "    #     val_loader   = DataLoader(val_sub,   batch_size=batch_size, shuffle=True)\n",
        "        \n",
        "\t\t\n",
        "    #     # model = Classifier(input_dim=input_dim, hidden_layers=hidden_layers, hidden_dim=hidden_dim).to(device)\n",
        "\t# \t# — Option B: RNN sequence labeling —\n",
        "    #     feat_dim = input_dim // concat_nframes\n",
        "\t# \t# model = RNNClassifier(\n",
        "\t# \t#     feat_dim, hidden_dim=128, num_layers=2,\n",
        "\t# \t#     num_classes=41, bidirectional=True, dropout=0.3\n",
        "\t# \t# ).to(device)\n",
        "    #     model = ConvLSTMClassifier(\n",
        "    #         input_dim=feat_dim,\n",
        "    #         hidden_dim=hidden_dim,\n",
        "    #         num_layers=hidden_layers,\n",
        "    #         num_classes=41,\n",
        "    #         conv_channels=config['conv_channels'],\n",
        "    #         bidirectional=True,\n",
        "    #         dropout=config['dropout']\n",
        "    #     ).to(device)\n",
        "\n",
        "\t# \t# ── TensorBoard writer per fold ──\n",
        "    #     writer = SummaryWriter(log_dir=f\"runs/exp_kfold/fold{fold}\")\n",
        "\n",
        "    #     print(f\"\\n=== Starting Fold {fold}/{k} ===\")\n",
        "    #     best_val = train_one_fold(fold, model, train_loader, val_loader,\n",
        "\t# \t\t\t\t\t\tepochs=num_epoch, lr=learning_rate, device=device, ckpt_path=\"./model\", writer=writer,weights=weights)\n",
        "    #     writer.close()\n",
        "\n",
        "    #     print(f\"Fold {fold} best val acc: {best_val:.4f}\\n\")\n",
        "    #     fold_accuracies.append(best_val)\n",
        "\n",
        "    # avg_acc = sum(fold_accuracies) / k\n",
        "    # print(f\"Average CV accuracy over {k} folds: {avg_acc:.4f}\")\n",
        "    return avg_acc\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Start Train!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "hyper-parameter:\n",
            "        lr: 0.005,\n",
            "        concat_nframes: 61\n",
            "[Dataset] train - samples: 2743\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2743/2743 [00:13<00:00, 206.11it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO] train set loaded.\n",
            "[Dataset] val - samples: 686\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 686/686 [00:08<00:00, 78.65it/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO] val set loaded.\n",
            "Model summary:\n",
            "input_norm.weight 2379\n",
            "input_norm.bias 2379\n",
            "lstm.weight_ih_l0 2436096\n",
            "lstm.weight_hh_l0 262144\n",
            "lstm.bias_ih_l0 1024\n",
            "lstm.bias_hh_l0 1024\n",
            "lstm.weight_ih_l0_reverse 2436096\n",
            "lstm.weight_hh_l0_reverse 262144\n",
            "lstm.bias_ih_l0_reverse 1024\n",
            "lstm.bias_hh_l0_reverse 1024\n",
            "lstm.weight_ih_l1 524288\n",
            "lstm.weight_hh_l1 262144\n",
            "lstm.bias_ih_l1 1024\n",
            "lstm.bias_hh_l1 1024\n",
            "lstm.weight_ih_l1_reverse 524288\n",
            "lstm.weight_hh_l1_reverse 262144\n",
            "lstm.bias_ih_l1_reverse 1024\n",
            "lstm.bias_hh_l1_reverse 1024\n",
            "lstm.weight_ih_l2 524288\n",
            "lstm.weight_hh_l2 262144\n",
            "lstm.bias_ih_l2 1024\n",
            "lstm.bias_hh_l2 1024\n",
            "lstm.weight_ih_l2_reverse 524288\n",
            "lstm.weight_hh_l2_reverse 262144\n",
            "lstm.bias_ih_l2_reverse 1024\n",
            "lstm.bias_hh_l2_reverse 1024\n",
            "lstm.weight_ih_l3 524288\n",
            "lstm.weight_hh_l3 262144\n",
            "lstm.bias_ih_l3 1024\n",
            "lstm.bias_hh_l3 1024\n",
            "lstm.weight_ih_l3_reverse 524288\n",
            "lstm.weight_hh_l3_reverse 262144\n",
            "lstm.bias_ih_l3_reverse 1024\n",
            "lstm.bias_hh_l3_reverse 1024\n",
            "output_norm.weight 512\n",
            "output_norm.bias 512\n",
            "output_proj.weight 20992\n",
            "output_proj.bias 41\n",
            "\n",
            "=== Epoch 1 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train Epoch 1: 100%|██████████| 172/172 [02:06<00:00,  1.36it/s, acc=0.396, loss=1.77]\n",
            "Val Epoch 1: 100%|██████████| 43/43 [00:36<00:00,  1.17it/s, acc=0.534, loss=1.82]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Epoch 2 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train Epoch 2: 100%|██████████| 172/172 [01:41<00:00,  1.70it/s, acc=0.605, loss=1.18]\n",
            "Val Epoch 2: 100%|██████████| 43/43 [00:11<00:00,  3.91it/s, acc=0.656, loss=1.21]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Epoch 3 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train Epoch 3: 100%|██████████| 172/172 [01:37<00:00,  1.77it/s, acc=0.663, loss=1.09]\n",
            "Val Epoch 3: 100%|██████████| 43/43 [00:26<00:00,  1.62it/s, acc=0.694, loss=1.11] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Epoch 4 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train Epoch 4: 100%|██████████| 172/172 [01:46<00:00,  1.62it/s, acc=0.692, loss=0.932]\n",
            "Val Epoch 4: 100%|██████████| 43/43 [00:18<00:00,  2.27it/s, acc=0.721, loss=0.969]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Epoch 5 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train Epoch 5: 100%|██████████| 172/172 [02:51<00:00,  1.00it/s, acc=0.708, loss=0.856]\n",
            "Val Epoch 5: 100%|██████████| 43/43 [00:20<00:00,  2.13it/s, acc=0.736, loss=1.02] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Epoch 6 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train Epoch 6: 100%|██████████| 172/172 [02:50<00:00,  1.01it/s, acc=0.719, loss=1.04] \n",
            "Val Epoch 6: 100%|██████████| 43/43 [00:15<00:00,  2.69it/s, acc=0.739, loss=0.911]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Epoch 7 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train Epoch 7: 100%|██████████| 172/172 [02:49<00:00,  1.01it/s, acc=0.724, loss=0.822]\n",
            "Val Epoch 7: 100%|██████████| 43/43 [00:21<00:00,  1.98it/s, acc=0.738, loss=0.902]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Epoch 8 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train Epoch 8: 100%|██████████| 172/172 [02:57<00:00,  1.03s/it, acc=0.731, loss=0.807]\n",
            "Val Epoch 8: 100%|██████████| 43/43 [00:19<00:00,  2.19it/s, acc=0.753, loss=0.888]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Epoch 9 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train Epoch 9: 100%|██████████| 172/172 [02:44<00:00,  1.05it/s, acc=0.74, loss=0.933] \n",
            "Val Epoch 9: 100%|██████████| 43/43 [00:21<00:00,  1.99it/s, acc=0.773, loss=0.779]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Epoch 10 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train Epoch 10: 100%|██████████| 172/172 [02:43<00:00,  1.05it/s, acc=0.743, loss=1.24] \n",
            "Val Epoch 10: 100%|██████████| 43/43 [00:17<00:00,  2.40it/s, acc=0.762, loss=0.8]  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Epoch 11 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train Epoch 11: 100%|██████████| 172/172 [03:08<00:00,  1.09s/it, acc=0.747, loss=0.816]\n",
            "Val Epoch 11: 100%|██████████| 43/43 [00:27<00:00,  1.59it/s, acc=0.767, loss=0.846]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Epoch 12 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train Epoch 12: 100%|██████████| 172/172 [03:07<00:00,  1.09s/it, acc=0.751, loss=0.881]\n",
            "Val Epoch 12: 100%|██████████| 43/43 [00:24<00:00,  1.75it/s, acc=0.773, loss=0.762]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Epoch 13 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train Epoch 13: 100%|██████████| 172/172 [03:14<00:00,  1.13s/it, acc=0.753, loss=1.09] \n",
            "Val Epoch 13: 100%|██████████| 43/43 [00:26<00:00,  1.63it/s, acc=0.773, loss=0.786]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Epoch 14 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train Epoch 14: 100%|██████████| 172/172 [03:10<00:00,  1.11s/it, acc=0.758, loss=1.09] \n",
            "Val Epoch 14: 100%|██████████| 43/43 [00:20<00:00,  2.10it/s, acc=0.779, loss=0.754]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Epoch 15 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train Epoch 15: 100%|██████████| 172/172 [03:20<00:00,  1.17s/it, acc=0.759, loss=0.953]\n",
            "Val Epoch 15: 100%|██████████| 43/43 [00:26<00:00,  1.65it/s, acc=0.774, loss=0.785]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Epoch 16 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train Epoch 16: 100%|██████████| 172/172 [03:22<00:00,  1.18s/it, acc=0.762, loss=0.926]\n",
            "Val Epoch 16: 100%|██████████| 43/43 [00:24<00:00,  1.76it/s, acc=0.782, loss=0.738]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Epoch 17 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train Epoch 17: 100%|██████████| 172/172 [03:17<00:00,  1.15s/it, acc=0.765, loss=0.937]\n",
            "Val Epoch 17: 100%|██████████| 43/43 [00:24<00:00,  1.79it/s, acc=0.792, loss=0.749]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Epoch 18 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train Epoch 18: 100%|██████████| 172/172 [03:27<00:00,  1.21s/it, acc=0.766, loss=0.742]\n",
            "Val Epoch 18: 100%|██████████| 43/43 [00:23<00:00,  1.83it/s, acc=0.789, loss=0.746]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Epoch 19 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train Epoch 19: 100%|██████████| 172/172 [03:11<00:00,  1.11s/it, acc=0.767, loss=0.801]\n",
            "Val Epoch 19: 100%|██████████| 43/43 [00:20<00:00,  2.07it/s, acc=0.793, loss=0.68] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Epoch 20 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train Epoch 20: 100%|██████████| 172/172 [03:22<00:00,  1.18s/it, acc=0.767, loss=0.792]\n",
            "Val Epoch 20: 100%|██████████| 43/43 [00:22<00:00,  1.94it/s, acc=0.789, loss=0.753]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Epoch 21 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train Epoch 21: 100%|██████████| 172/172 [04:08<00:00,  1.44s/it, acc=0.769, loss=0.793]\n",
            "Val Epoch 21: 100%|██████████| 43/43 [00:41<00:00,  1.03it/s, acc=0.795, loss=0.697]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Epoch 22 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train Epoch 22: 100%|██████████| 172/172 [03:06<00:00,  1.09s/it, acc=0.769, loss=0.764]\n",
            "Val Epoch 22: 100%|██████████| 43/43 [00:22<00:00,  1.93it/s, acc=0.791, loss=0.62] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Epoch 23 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train Epoch 23: 100%|██████████| 172/172 [03:03<00:00,  1.06s/it, acc=0.772, loss=0.664]\n",
            "Val Epoch 23: 100%|██████████| 43/43 [00:26<00:00,  1.61it/s, acc=0.786, loss=0.67] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Epoch 24 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train Epoch 24: 100%|██████████| 172/172 [03:06<00:00,  1.08s/it, acc=0.772, loss=0.689]\n",
            "Val Epoch 24: 100%|██████████| 43/43 [00:16<00:00,  2.61it/s, acc=0.794, loss=0.685]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Epoch 25 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train Epoch 25: 100%|██████████| 172/172 [02:48<00:00,  1.02it/s, acc=0.772, loss=1.11] \n",
            "Val Epoch 25: 100%|██████████| 43/43 [00:20<00:00,  2.15it/s, acc=0.792, loss=0.702]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Epoch 26 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train Epoch 26: 100%|██████████| 172/172 [03:09<00:00,  1.10s/it, acc=0.775, loss=0.711]\n",
            "Val Epoch 26: 100%|██████████| 43/43 [00:25<00:00,  1.66it/s, acc=0.788, loss=0.723]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Epoch 27 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train Epoch 27: 100%|██████████| 172/172 [03:27<00:00,  1.21s/it, acc=0.777, loss=0.723]\n",
            "Val Epoch 27: 100%|██████████| 43/43 [00:27<00:00,  1.59it/s, acc=0.797, loss=0.697]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Epoch 28 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train Epoch 28: 100%|██████████| 172/172 [03:05<00:00,  1.08s/it, acc=0.776, loss=0.864]\n",
            "Val Epoch 28: 100%|██████████| 43/43 [00:27<00:00,  1.55it/s, acc=0.795, loss=0.719]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Epoch 29 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train Epoch 29: 100%|██████████| 172/172 [03:08<00:00,  1.09s/it, acc=0.772, loss=0.938]\n",
            "Val Epoch 29: 100%|██████████| 43/43 [00:18<00:00,  2.37it/s, acc=0.791, loss=0.657]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Epoch 30 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train Epoch 30: 100%|██████████| 172/172 [03:03<00:00,  1.07s/it, acc=0.776, loss=0.819]\n",
            "Val Epoch 30: 100%|██████████| 43/43 [00:20<00:00,  2.05it/s, acc=0.799, loss=0.661]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Epoch 31 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train Epoch 31: 100%|██████████| 172/172 [03:12<00:00,  1.12s/it, acc=0.777, loss=0.783]\n",
            "Val Epoch 31: 100%|██████████| 43/43 [00:30<00:00,  1.41it/s, acc=0.8, loss=0.659]  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Epoch 32 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train Epoch 33: 100%|██████████| 172/172 [03:20<00:00,  1.17s/it, acc=0.777, loss=0.857]\n",
            "Val Epoch 33: 100%|██████████| 43/43 [00:29<00:00,  1.47it/s, acc=0.806, loss=0.634]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Epoch 34 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train Epoch 34: 100%|██████████| 172/172 [03:18<00:00,  1.15s/it, acc=0.779, loss=0.847]\n",
            "Val Epoch 34: 100%|██████████| 43/43 [00:26<00:00,  1.60it/s, acc=0.805, loss=0.609]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Epoch 35 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train Epoch 35: 100%|██████████| 172/172 [03:14<00:00,  1.13s/it, acc=0.78, loss=0.674] \n",
            "Val Epoch 35: 100%|██████████| 43/43 [00:38<00:00,  1.12it/s, acc=0.802, loss=0.618]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Epoch 36 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train Epoch 36: 100%|██████████| 172/172 [05:27<00:00,  1.90s/it, acc=0.779, loss=0.783]\n",
            "Val Epoch 36: 100%|██████████| 43/43 [00:40<00:00,  1.05it/s, acc=0.802, loss=0.684]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Epoch 37 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train Epoch 37: 100%|██████████| 172/172 [03:17<00:00,  1.15s/it, acc=0.78, loss=0.9]   \n",
            "Val Epoch 37: 100%|██████████| 43/43 [00:28<00:00,  1.51it/s, acc=0.807, loss=0.643]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Epoch 38 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train Epoch 38: 100%|██████████| 172/172 [03:08<00:00,  1.10s/it, acc=0.78, loss=0.807] \n",
            "Val Epoch 38: 100%|██████████| 43/43 [00:21<00:00,  2.02it/s, acc=0.804, loss=0.626]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Epoch 39 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train Epoch 39: 100%|██████████| 172/172 [03:31<00:00,  1.23s/it, acc=0.78, loss=0.839] \n",
            "Val Epoch 39: 100%|██████████| 43/43 [00:29<00:00,  1.46it/s, acc=0.802, loss=0.614]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Epoch 40 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train Epoch 40: 100%|██████████| 172/172 [03:30<00:00,  1.22s/it, acc=0.794, loss=0.792]\n",
            "Val Epoch 40: 100%|██████████| 43/43 [00:28<00:00,  1.51it/s, acc=0.818, loss=0.583]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Epoch 41 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train Epoch 41: 100%|██████████| 172/172 [03:01<00:00,  1.05s/it, acc=0.797, loss=0.666]\n",
            "Val Epoch 41: 100%|██████████| 43/43 [00:26<00:00,  1.63it/s, acc=0.819, loss=0.607]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Epoch 42 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train Epoch 42: 100%|██████████| 172/172 [03:22<00:00,  1.18s/it, acc=0.797, loss=0.841]\n",
            "Val Epoch 42: 100%|██████████| 43/43 [00:29<00:00,  1.44it/s, acc=0.805, loss=0.605]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Epoch 43 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train Epoch 43:  52%|█████▏    | 89/172 [01:25<01:22,  1.01it/s, acc=0.799, loss=0.603]"
          ]
        }
      ],
      "source": [
        "AUTO_TUNE_PARAM = False  # Whether to tune parameters automatically\n",
        "\n",
        "if AUTO_TUNE_PARAM:\n",
        "    # 使用Optuna库进行超参数搜索\n",
        "    n_trials = 5  # 设置试验数量\n",
        "    print(f'n_trials: {n_trials}')\n",
        "    study = optuna.create_study(direction='maximize')\n",
        "    study.optimize(objective, n_trials=n_trials)\n",
        "    optuna.visualization.plot_param_importances(study).show()\n",
        "    optuna.visualization.plot_optimization_history(study).show()\n",
        "    optuna.visualization.plot_slice(study).show()\n",
        "\n",
        "    # 输出最优的超参数组合和性能指标\n",
        "    print('Best hyperparameters: {}'.format(study.best_params))\n",
        "    print('Best performance: {:.4f}'.format(study.best_value))\n",
        "else:\n",
        "    objective(None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Validation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Dataset] train - samples: 2743\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2743/2743 [00:19<00:00, 138.31it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO] train set loaded.\n",
            "[Dataset] val - samples: 686\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 686/686 [00:06<00:00, 114.25it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO] val set loaded.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 43/43 [00:08<00:00,  4.93it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.988     0.967     0.977     72727\n",
            "           1      0.925     0.720     0.810      2280\n",
            "           2      0.955     0.958     0.957     22769\n",
            "           3      0.929     0.940     0.935      5593\n",
            "           4      0.920     0.911     0.916     19649\n",
            "           5      0.926     0.909     0.917     19548\n",
            "           6      0.942     0.951     0.946     10408\n",
            "           7      0.909     0.929     0.919      2490\n",
            "           8      0.934     0.942     0.938     10598\n",
            "           9      0.938     0.945     0.942      6904\n",
            "          10      0.949     0.969     0.959      9408\n",
            "          11      0.932     0.968     0.950      4295\n",
            "          12      0.935     0.943     0.939      6653\n",
            "          13      0.914     0.955     0.934      4048\n",
            "          14      0.964     0.967     0.966      8327\n",
            "          15      0.894     0.942     0.917      4788\n",
            "          16      0.912     0.962     0.937      2869\n",
            "          17      0.966     0.920     0.943       981\n",
            "          18      0.913     0.919     0.916      2142\n",
            "          19      0.905     0.900     0.902     13415\n",
            "          20      0.948     0.993     0.970       146\n",
            "          21      0.932     0.949     0.941      2816\n",
            "          22      0.894     0.912     0.903      1274\n",
            "          23      0.934     0.957     0.945      7398\n",
            "          24      0.916     0.923     0.920      5570\n",
            "          25      0.927     0.940     0.934     10922\n",
            "          26      0.923     0.945     0.934      6046\n",
            "          27      0.906     0.901     0.904     16445\n",
            "          28      0.922     0.944     0.933      9713\n",
            "          29      0.906     0.933     0.919      6228\n",
            "          30      0.931     0.932     0.931     13659\n",
            "          31      0.918     0.895     0.906     24725\n",
            "          32      0.923     0.948     0.935      6799\n",
            "          33      0.919     0.958     0.938      7190\n",
            "          34      0.938     0.947     0.943      3623\n",
            "          35      0.919     0.934     0.927      7803\n",
            "          36      0.922     0.930     0.926     11590\n",
            "          37      0.929     0.924     0.927     12963\n",
            "          38      0.889     0.909     0.899      2550\n",
            "          39      0.943     0.949     0.946     15116\n",
            "          40      0.921     0.921     0.921      9790\n",
            "\n",
            "    accuracy                          0.937    412258\n",
            "   macro avg      0.927     0.933     0.930    412258\n",
            "weighted avg      0.938     0.937     0.937    412258\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "config['concat_nframes'] = 61\n",
        "input_dim = 39 * config['concat_nframes'] # the input dim of the model, you should not change the value\n",
        "\n",
        "# preprocess data\n",
        "train_X, train_y = preprocess_data(split='train', feat_dir='./mlhw2/libriphone/feat', phone_path='./mlhw2/libriphone', concat_nframes=concat_nframes, train_ratio=train_ratio)\n",
        "val_X, val_y = preprocess_data(split='val', feat_dir='./mlhw2/libriphone/feat', phone_path='./mlhw2/libriphone', concat_nframes=concat_nframes, train_ratio=train_ratio)\n",
        "\n",
        "# get dataset\n",
        "train_set = LibriSequenceDataset(train_X, train_y)\n",
        "val_set = LibriSequenceDataset(val_X, val_y)\n",
        "\n",
        "# remove raw feature to save memory\n",
        "del train_X, train_y, val_X, val_y\n",
        "gc.collect()\n",
        "\n",
        "# get dataloader\n",
        "# train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
        "# val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False)\n",
        "train_loader = DataLoader(\n",
        "    train_set,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    collate_fn=collate_fn\n",
        ")\n",
        "val_loader = DataLoader(\n",
        "    val_set,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,\n",
        "    collate_fn=collate_fn\n",
        ")\n",
        "\n",
        "# load model\n",
        "feat_dim = input_dim // concat_nframes\n",
        "model = RNNClassifier(\n",
        "    input_dim, hidden_dim=hidden_dim, num_layers=hidden_layers,\n",
        "    num_classes=41, bidirectional=True, dropout=config['dropout']\n",
        ").to(device)\n",
        "# model = ConvLSTMClassifier(\n",
        "#     input_dim=feat_dim,\n",
        "#     hidden_dim=hidden_dim,\n",
        "#     num_layers=hidden_layers,\n",
        "#     num_classes=41,\n",
        "#     conv_channels=config['conv_channels'],\n",
        "#     bidirectional=True,\n",
        "#     dropout=config['dropout']\n",
        "# ).to(device)\n",
        "model.load_state_dict(torch.load(config['save_path']))\n",
        "\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for feats, labels, lengths in tqdm(val_loader):  # 或 test_loader\n",
        "        feat_dim = feats.size(1) // concat_nframes\n",
        "        feats = feats.to(device)\n",
        "        labels = labels.to(device)\n",
        "        lengths = lengths.to('cpu')  # 注意 pack_padded_sequence 要用 CPU 上的长度列表\n",
        "        out = model(feats, lengths)\n",
        "\n",
        "        # outputs = model(feats)\n",
        "        pred = out.argmax(dim=-1)            # (B, T)\n",
        "        mask = (labels != -100)              # padding mask\n",
        "        correct = ((pred == labels) & mask).sum().item()\n",
        "        all_preds.extend(pred[mask].cpu().numpy())\n",
        "        all_labels.extend(labels[mask].cpu().numpy())\n",
        "\n",
        "# 打印分类报告\n",
        "print(classification_report(all_labels, all_preds, digits=3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Hi7jTn3PX-m"
      },
      "source": [
        "# Testing\n",
        "Create a testing dataset, and load model from the saved checkpoint."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-02-22T15:23:24.813902Z",
          "iopub.status.busy": "2023-02-22T15:23:24.813496Z",
          "iopub.status.idle": "2023-02-22T15:23:29.53993Z",
          "shell.execute_reply": "2023-02-22T15:23:29.538893Z",
          "shell.execute_reply.started": "2023-02-22T15:23:24.813865Z"
        },
        "id": "VOG1Ou0PGrhc",
        "trusted": true,
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Dataset] test - samples: 857\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 857/857 [00:04<00:00, 173.92it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO] test set loaded.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "config['concat_nframes'] = 61\n",
        "input_dim = 39 * config['concat_nframes'] # the input dim of the model, you should not change the value\n",
        "\n",
        "# load model\n",
        "feat_dim = input_dim // concat_nframes\n",
        "# model = RNNClassifier(\n",
        "#     feat_dim, hidden_dim=hidden_dim, num_layers=hidden_layers,\n",
        "#     num_classes=41, bidirectional=True, dropout=config['dropout']\n",
        "# ).to(device)\n",
        "\n",
        "# model = ConvLSTMClassifier(\n",
        "#     input_dim=feat_dim,\n",
        "#     hidden_dim=hidden_dim,\n",
        "#     num_layers=hidden_layers,\n",
        "#     num_classes=41,\n",
        "#     conv_channels=config['conv_channels'],\n",
        "#     bidirectional=True,\n",
        "#     dropout=config['dropout']\n",
        "# ).to(device)\n",
        "model = RNNClassifier(\n",
        "    input_dim, hidden_dim=hidden_dim, num_layers=hidden_layers,\n",
        "    num_classes=41, bidirectional=True, dropout=config['dropout']\n",
        ").to(device)\n",
        "\n",
        "model.load_state_dict(torch.load(config['save_path']))\n",
        "\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "def collate_fn_test(batch):\n",
        "    # batch: list of (x, length)\n",
        "    xs, lengths = zip(*batch)\n",
        "    xs_pad = pad_sequence(xs, batch_first=True)\n",
        "    return xs_pad, torch.tensor(lengths)\n",
        "\n",
        "# load data\n",
        "test_X = preprocess_data(split='test', feat_dir='./mlhw2/libriphone/feat', phone_path='./mlhw2/libriphone', concat_nframes=config['concat_nframes'])\n",
        "test_set = LibriSequenceDataset(test_X, None)\n",
        "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False, collate_fn=collate_fn_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zp-DV1p4r7Nz"
      },
      "source": [
        "Make prediction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "print(np.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-02-22T15:23:29.561203Z",
          "iopub.status.busy": "2023-02-22T15:23:29.560613Z",
          "iopub.status.idle": "2023-02-22T15:23:31.628018Z",
          "shell.execute_reply": "2023-02-22T15:23:31.626836Z",
          "shell.execute_reply.started": "2023-02-22T15:23:29.561164Z"
        },
        "id": "84HU5GGjPqR0",
        "trusted": true,
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 54/54 [00:10<00:00,  5.14it/s]\n"
          ]
        }
      ],
      "source": [
        "pred = np.array([], dtype=np.int32)\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for feats, lengths in tqdm(test_loader):\n",
        "        # features = batch\n",
        "        # features = features.to(device)\n",
        "        # feat_dim = feats.size(1) // concat_nframes\n",
        "        # feats = feats.view(-1, concat_nframes, feat_dim).to(device)\n",
        "        feats = feats.to(device)\n",
        "        lengths = lengths.to('cpu')  # 注意 pack_padded_sequence 要用 CPU 上的长度列表\n",
        "        out = model(feats, lengths)\n",
        "        pred_batch = out.argmax(dim=-1)      # (B, T)\n",
        "        \n",
        "        for i in range(pred_batch.size(0)):\n",
        "            valid_len = lengths[i]\n",
        "            pred = np.concatenate((pred,pred_batch[i, :valid_len].cpu().numpy()),axis=0)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wyZqy40Prz0v"
      },
      "source": [
        "Write prediction to a CSV file.\n",
        "\n",
        "After finish running this block, download the file `prediction.csv` from the files section on the left-hand side and submit it to Kaggle."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-02-22T15:23:31.631536Z",
          "iopub.status.busy": "2023-02-22T15:23:31.630344Z",
          "iopub.status.idle": "2023-02-22T15:23:32.063028Z",
          "shell.execute_reply": "2023-02-22T15:23:32.061992Z",
          "shell.execute_reply.started": "2023-02-22T15:23:31.631476Z"
        },
        "id": "GuljYSPHcZir",
        "trusted": true,
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "with open('prediction.csv', 'w') as f:\n",
        "    f.write('Id,Class\\n')\n",
        "    for i, y in enumerate(pred):\n",
        "        f.write('{},{}\\n'.format(i, y))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "ML2023Spring - HW2",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "",
      "version": ""
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
